{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca8c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1297/1297 [==============================] - 23s 16ms/step - loss: 0.1939 - accuracy: 0.9179\n",
      "Epoch 2/100\n",
      "1297/1297 [==============================] - 20s 16ms/step - loss: 0.1320 - accuracy: 0.9461\n",
      "Epoch 3/100\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.1155 - accuracy: 0.9516\n",
      "Epoch 4/100\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.1089 - accuracy: 0.9543\n",
      "Epoch 5/100\n",
      "1297/1297 [==============================] - 21s 16ms/step - loss: 0.1001 - accuracy: 0.9585\n",
      "Epoch 6/100\n",
      "1297/1297 [==============================] - 21s 16ms/step - loss: 0.0946 - accuracy: 0.9601\n",
      "Epoch 7/100\n",
      "1297/1297 [==============================] - 21s 16ms/step - loss: 0.0872 - accuracy: 0.9635\n",
      "Epoch 8/100\n",
      "1297/1297 [==============================] - 19s 15ms/step - loss: 0.0830 - accuracy: 0.9645\n",
      "Epoch 9/100\n",
      "1297/1297 [==============================] - 19s 15ms/step - loss: 0.0808 - accuracy: 0.9654\n",
      "Epoch 10/100\n",
      "1297/1297 [==============================] - 19s 15ms/step - loss: 0.0776 - accuracy: 0.9674\n",
      "Epoch 11/100\n",
      "1297/1297 [==============================] - 19s 15ms/step - loss: 0.0735 - accuracy: 0.9699\n",
      "Epoch 12/100\n",
      "1297/1297 [==============================] - 19s 15ms/step - loss: 0.0699 - accuracy: 0.9708\n",
      "Epoch 13/100\n",
      "1297/1297 [==============================] - 21s 16ms/step - loss: 0.0673 - accuracy: 0.9717\n",
      "Epoch 14/100\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.0631 - accuracy: 0.9733\n",
      "Epoch 15/100\n",
      "1297/1297 [==============================] - 20s 16ms/step - loss: 0.0614 - accuracy: 0.9743\n",
      "Epoch 16/100\n",
      "1297/1297 [==============================] - 21s 16ms/step - loss: 0.0590 - accuracy: 0.9755\n",
      "Epoch 17/100\n",
      " 477/1297 [==========>...................] - ETA: 13s - loss: 0.0527 - accuracy: 0.9794"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "# 학습 데이터 준비\n",
    "csv_file_path1 = r\"C:\\Users\\권현주\\Downloads\\한국언론진흥재단_뉴스빅데이터_메타데이터_가짜뉴스_20201231.csv\"\n",
    "csv_file_path2 = r\"C:\\Users\\권현주\\Desktop\\asdf.csv\"\n",
    "df2 = pd.read_csv(csv_file_path2)\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "\n",
    "df1['참과 거짓'] = 0\n",
    "df2['참과 거짓'] = 1\n",
    "df2.rename(columns={'특성추출(가중치순 상위 50개)':'특성추출'},inplace = True)\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df = df.drop(['통합 분류1', '통합 분류2', '통합 분류3', '사건_사고 분류1', '사건_사고 분류2', '사건_사고 분류3', '개체명(인물)', '개체명(지역)', '개체명(기업기관)'], axis=1)\n",
    "df_train = df\n",
    "df_train['본문'] = df_train['본문'].astype(str)\n",
    "\n",
    "\n",
    "# 텍스트 전처리\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train['본문'])\n",
    "sequences = tokenizer.texts_to_sequences(df_train['본문'])\n",
    "max_length = max(len(sequence) for sequence in sequences)  # 입력 시퀀스 최대 길이\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# 입력 데이터와 레이블을 Tensor로 변환\n",
    "train_data = tf.convert_to_tensor(padded_sequences)\n",
    "train_labels = tf.convert_to_tensor(df_train['참과 거짓'])\n",
    "\n",
    "\n",
    "# 단어 집합 크기 설정\n",
    "vocab_size = len(tokenizer.word_index) + 1  # 단어 집합 크기 계산\n",
    "\n",
    "\n",
    "# Word2Vec 모델 훈련\n",
    "embedding_dim = 100  # Word2Vec 임베딩 벡터 차원 수\n",
    "sentences = [tokenizer.sequences_to_texts([sequence.numpy()])[0].split() for sequence in train_data]\n",
    "w2v_model = Word2Vec(sentences=sentences, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
    "\n",
    "# LSTM 모델 생성\n",
    "hidden_units = 64  # LSTM 레이어의 유닛 수\n",
    "num_classes = 2  # 분류할 클래스(레이블) 수\n",
    "num_epochs = 100  # 학습 반복 횟수\n",
    "batch_size = 32  # 미니배치 크기\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[idx] = w2v_model.wv[word]\n",
    "\n",
    "# LSTM 모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length,\n",
    "                              weights=[embedding_matrix], trainable=False),\n",
    "    tf.keras.layers.LSTM(units=hidden_units),\n",
    "    tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_data, train_labels, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "csv_file_path2 = r\"C:\\Users\\권현주\\Downloads\\한국언론진흥재단_뉴스빅데이터_메타데이터_청와대_19971231.csv\"\n",
    "td = pd.read_csv(csv_file_path2, encoding='cp949')\n",
    "# 테스트 데이터 준비\n",
    "test_data = td\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# 입력 데이터를 Tensor로 변환\n",
    "test_data = tf.convert_to_tensor(test_sequences)\n",
    "\n",
    "# 모델 예측\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 예측 결과 출력\n",
    "fake_news_count = 0\n",
    "for i, predicted_label in enumerate(predicted_labels):\n",
    "    if predicted_label == 0:\n",
    "            fake_news_count += 1\n",
    "print(f\"전체 테스트 데이터 중 가짜뉴스 개수: {fake_news_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path2 = r\"C:\\Users\\권현주\\Downloads\\한국언론진흥재단_뉴스빅데이터_메타데이터_가짜뉴스_20201231 (1).csv\"\n",
    "td = pd.read_csv(csv_file_path2, encoding='cp949')\n",
    "# 테스트 데이터 준비\n",
    "test_data = td\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# 입력 데이터를 Tensor로 변환\n",
    "test_data = tf.convert_to_tensor(test_sequences)\n",
    "\n",
    "# 모델 예측\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 예측 결과 출력\n",
    "fake_news_count = 0\n",
    "for i, predicted_label in enumerate(predicted_labels):\n",
    "    if predicted_label == 0:\n",
    "            fake_news_count += 1\n",
    "print(f\"전체 테스트 데이터 중 가짜뉴스 개수: {fake_news_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c23356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 예측 결과 출력\n",
    "fake_news_count = 0\n",
    "for i, predicted_label in enumerate(predicted_labels):\n",
    "    if predicted_label == 0:\n",
    "        fake_news_count += 1\n",
    "print(f\"전체 테스트 데이터 중 가짜뉴스 개수: {fake_news_count}\")\n",
    "\n",
    "# 가짜뉴스로 예측된 뉴스의 인덱스 출력\n",
    "fake_news_indices = []\n",
    "for i, predicted_label in enumerate(predicted_labels):\n",
    "    if predicted_label == 0:\n",
    "        fake_news_indices.append(i)\n",
    "\n",
    "print(\"가짜뉴스로 예측된 뉴스의 인덱스:\")\n",
    "for idx in fake_news_indices:\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "274cf799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주소</th>\n",
       "      <th>일자</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기고자</th>\n",
       "      <th>제목</th>\n",
       "      <th>키워드</th>\n",
       "      <th>특성추출</th>\n",
       "      <th>본문</th>\n",
       "      <th>원본주소</th>\n",
       "      <th>참과 거짓</th>\n",
       "      <th>인물</th>\n",
       "      <th>위치</th>\n",
       "      <th>기관</th>\n",
       "      <th>특성추출(가중치순 상위 50개)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bigkinds.or.kr/news/newsDetailView....</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>조선일보</td>\n",
       "      <td>워싱턴/김신영 기자</td>\n",
       "      <td>진짜뉴스는 비싸다, 때론 목숨까지 건다</td>\n",
       "      <td>진짜뉴스,목숨,조선일보,진실,수호자들,저널리즘,도전,민주주의,위협,가짜,전쟁,거짓,...</td>\n",
       "      <td>뉴지엄,박물관,추모관,미국,로스앤젤레스타임스,전시물,캐논,비가트,패런솔드,기자들,워...</td>\n",
       "      <td>미국 워싱턴DC 국회의사당 부근 뉴스 박물관인 뉴지엄(Newseum) 3층엔 세상을...</td>\n",
       "      <td>https://news.chosun.com/site/data/html_dir/202...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.bigkinds.or.kr/news/newsDetailView....</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>김규리</td>\n",
       "      <td>라임사태 피해 투자자들 대규모 법정대응 예고…`불완전 판매` 여부 핵심</td>\n",
       "      <td>라임,사태,피해,투자자,법정,대응,예고,불완전,판매,여부,핵심,투자처,라임,자산,운...</td>\n",
       "      <td>라임자산운용,투자자,광화,iig,투자자들,헤지펀드,미국,무역금융펀드,등록취소,판매사...</td>\n",
       "      <td>라임자산운용 무역금융펀드 투자처인 미국 헤지펀드 운용사가 등록취소 제재를 받으면서 ...</td>\n",
       "      <td>http://news.mk.co.kr/newsRead.php?no=1773&amp;year...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.bigkinds.or.kr/news/newsDetailView....</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>아주경제</td>\n",
       "      <td>전환욱</td>\n",
       "      <td>​유성엽 “갈등·분노·혐오 사라지고 화합·통합의 새해 열리길”</td>\n",
       "      <td>유성엽,갈등,분노,혐오,화합,통합,새해,한국,통일,추진,세상,유성엽,대안,창당준비위...</td>\n",
       "      <td>위원장,유성엽,창당준비위원장,신년사,광주시당,중앙당,대한민국,강대국,일본,성원,광주...</td>\n",
       "      <td>유성엽 대안신당 창당준비위원장이 1일 신년사에서 ..“우리 사회의 건강한 발전을 가...</td>\n",
       "      <td>http://www.ajunews.com/view/20200101160438501</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.bigkinds.or.kr/news/newsDetailView....</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>SBS</td>\n",
       "      <td>김도균 기자</td>\n",
       "      <td>AI가 만든 '진짜 같은 가짜'…선거판에 악용될까 '우려'</td>\n",
       "      <td>AI,진짜,가짜,선거판,악용,앵커,인공지능,환영,악용,걱정,목소리,총선,미국,대선,...</td>\n",
       "      <td>딥페이크,인공지능,미국,중국,김도균,오바마,선거판,화면제공,이흥규,원형희,카이스트,...</td>\n",
       "      <td>&lt;앵커&gt; .. .. .. .. .. ..인공지능이 환영받기만 하는 건 아니지요, 기...</td>\n",
       "      <td>https://news.sbs.co.kr/news/endPage.do?news_id...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.bigkinds.or.kr/news/newsDetailView....</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>노현섭 기자</td>\n",
       "      <td>‘벵가지’ 악몽에 ‘이라크 美대사관 공격’ 강경 대응 나선 트럼프</td>\n",
       "      <td>벵가지,악몽,이라크,대사관,공격,강경,대응,트럼프,도널드,트럼프,미국,대통령,이라크...</td>\n",
       "      <td>벵가지,미국,이라크,대사관,행정부,클린턴,폼페이오,리비아,트윗,오바마,바그다드,워싱...</td>\n",
       "      <td>도널드 트럼프 미국 대통령이 이라크의 친이란 시아파 민병대 카티이브-헤즈볼라를 폭격...</td>\n",
       "      <td>http://www.sedaily.com/NewsView/1YXH7V9DCA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  주소          일자   언론사  \\\n",
       "0  http://www.bigkinds.or.kr/news/newsDetailView....  2020-01-01  조선일보   \n",
       "1  http://www.bigkinds.or.kr/news/newsDetailView....  2020-01-01  매일경제   \n",
       "2  http://www.bigkinds.or.kr/news/newsDetailView....  2020-01-01  아주경제   \n",
       "3  http://www.bigkinds.or.kr/news/newsDetailView....  2020-01-01   SBS   \n",
       "4  http://www.bigkinds.or.kr/news/newsDetailView....  2020-01-01  서울경제   \n",
       "\n",
       "          기고자                                       제목  \\\n",
       "0  워싱턴/김신영 기자                    진짜뉴스는 비싸다, 때론 목숨까지 건다   \n",
       "1         김규리  라임사태 피해 투자자들 대규모 법정대응 예고…`불완전 판매` 여부 핵심   \n",
       "2         전환욱       ​유성엽 “갈등·분노·혐오 사라지고 화합·통합의 새해 열리길”   \n",
       "3      김도균 기자         AI가 만든 '진짜 같은 가짜'…선거판에 악용될까 '우려'   \n",
       "4      노현섭 기자     ‘벵가지’ 악몽에 ‘이라크 美대사관 공격’ 강경 대응 나선 트럼프   \n",
       "\n",
       "                                                 키워드  \\\n",
       "0  진짜뉴스,목숨,조선일보,진실,수호자들,저널리즘,도전,민주주의,위협,가짜,전쟁,거짓,...   \n",
       "1  라임,사태,피해,투자자,법정,대응,예고,불완전,판매,여부,핵심,투자처,라임,자산,운...   \n",
       "2  유성엽,갈등,분노,혐오,화합,통합,새해,한국,통일,추진,세상,유성엽,대안,창당준비위...   \n",
       "3  AI,진짜,가짜,선거판,악용,앵커,인공지능,환영,악용,걱정,목소리,총선,미국,대선,...   \n",
       "4  벵가지,악몽,이라크,대사관,공격,강경,대응,트럼프,도널드,트럼프,미국,대통령,이라크...   \n",
       "\n",
       "                                                특성추출  \\\n",
       "0  뉴지엄,박물관,추모관,미국,로스앤젤레스타임스,전시물,캐논,비가트,패런솔드,기자들,워...   \n",
       "1  라임자산운용,투자자,광화,iig,투자자들,헤지펀드,미국,무역금융펀드,등록취소,판매사...   \n",
       "2  위원장,유성엽,창당준비위원장,신년사,광주시당,중앙당,대한민국,강대국,일본,성원,광주...   \n",
       "3  딥페이크,인공지능,미국,중국,김도균,오바마,선거판,화면제공,이흥규,원형희,카이스트,...   \n",
       "4  벵가지,미국,이라크,대사관,행정부,클린턴,폼페이오,리비아,트윗,오바마,바그다드,워싱...   \n",
       "\n",
       "                                                  본문  \\\n",
       "0  미국 워싱턴DC 국회의사당 부근 뉴스 박물관인 뉴지엄(Newseum) 3층엔 세상을...   \n",
       "1  라임자산운용 무역금융펀드 투자처인 미국 헤지펀드 운용사가 등록취소 제재를 받으면서 ...   \n",
       "2  유성엽 대안신당 창당준비위원장이 1일 신년사에서 ..“우리 사회의 건강한 발전을 가...   \n",
       "3  <앵커> .. .. .. .. .. ..인공지능이 환영받기만 하는 건 아니지요, 기...   \n",
       "4  도널드 트럼프 미국 대통령이 이라크의 친이란 시아파 민병대 카티이브-헤즈볼라를 폭격...   \n",
       "\n",
       "                                                원본주소  참과 거짓   인물   위치   기관  \\\n",
       "0  https://news.chosun.com/site/data/html_dir/202...      1  NaN  NaN  NaN   \n",
       "1  http://news.mk.co.kr/newsRead.php?no=1773&year...      1  NaN  NaN  NaN   \n",
       "2      http://www.ajunews.com/view/20200101160438501      1  NaN  NaN  NaN   \n",
       "3  https://news.sbs.co.kr/news/endPage.do?news_id...      1  NaN  NaN  NaN   \n",
       "4         http://www.sedaily.com/NewsView/1YXH7V9DCA      1  NaN  NaN  NaN   \n",
       "\n",
       "  특성추출(가중치순 상위 50개)  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
