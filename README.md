# Proxima-AI

Proxima AI는 가짜 뉴스 판별 AI입니다.

## 💡가짜 뉴스란?
사람들의 흥미와 본능을 자극하여 시선을 끄는 황색언론의 일종으로 여기서 황색언론이란 사람의 본능 즉 자극적인 요소를 이용한 저널리즘입니다.

## 💡Proxima AI의 원리
저희는 정확도가 가장 높은 **콘텐츠교차검증** 기술을 사용하였습니다. 콘텐츠교차 검증 기술을 사용하여 만든 인공지능의 원리는 이렇습니다. 크게 6단계로 **데이터 준비, 텍스트 전처리, Word2Vec 모델 훈련, LSTM 모델 생성, 모델 컴파일 및 학습, 테스트 데이터 전처리 및 예측**으로 구성되어 있습니다. 더 자세히 알아보겠습니다. 아래의 그림은 프록시마 AI의 작동 원리를 한 눈에 볼 수 있습니다.

<br><br>

![이미지](https://cdn.discordapp.com/attachments/1125809283301384296/1134103770356256849/image.png)

<br><br>

가장 먼저 두 개의 CSV 파일을 읽어옵니다. 첫 번째 파일은 가짜 뉴스 데이터, 두 번째 파일은 1인 가구 관련 뉴스 데이터입니다. 각 데이터 프레임에 '참과 거짓'열을 추가하여 가짜 뉴스를 레이블링합니다. 가짜 뉴스는 0으로, 1인 가구 뉴스는 1로 레이블링됩니다. 데이터 준비가 끝났다면 텍스트 전처리 단계입니다. 토크나이저라는 토큰화를 수행하는 프로그램을 사용하여 단어들을 토큰화 한 뒤 단어 집합을 생성하고, 텍스트 데이터를 시퀀스 형태로 변환합니다. 가장 긴 시퀀스의 길이를 찾아서 모든 시퀀스를 해당 길이로 통일화합니다. 데이터 전처리 이후 임베딩 모델인 Word2Vec 모델을 훈련시킵니다. Word2Vec 모델은 주어진 텍스트 데이터에서 단어들의 분산 표현인 임베딩 벡터를 학습하는 기법을 통해 훈련됩니다. 텍스트 데이터를 시퀀스로 변환한 뒤, Word2Vec 모델에 입력하여 단어들의 임베딩 벡터를 학습합니다. Word2Vec 모델이 준비되었다면 분류 모델 학습을 위해 LSTM 모델을 생성합니다. 임베딩 레이어는 Word2Vec에서 학습한 임베딩 벡터로 초기화됩니다. 이를 통해 사전 학습된 단어 임베딩을 활용하여 성능을 개선할 수 있습니다. LSTM 레이어를 사용하여 시퀀스 데이터를 처리하고, 마지막에 Dense 레이어로 분류를 수행하는 모델을 생성합니다. LSTM 모델은 최종적으로 가짜 뉴스의 개수를 카운팅하게 됩니다. 모든 모델이 준비되었다면 생성된 모델을 컴파일하고, 학습 데이터와 레이블을 사용하여 모델을 학습시킵니다. 마지막으로 테스트 데이터를 불러오고, 텍스트 전처리를 거치며 학습된 LSTM 모델을 사용하여 테스트 데이터를 예측하고, 가짜 뉴스의 개수를 카운팅합니다. 이런 방식을 통해 만든 인공지능이 바로 프록시마 AI입니다.

## 💡기대 효과
1. **가짜 뉴스 확산을 방지할 수 있습니다.** 대다수의 뉴스는 검증보다 전파되는 시간이 빨라서 갈수록 가짜 뉴스 확산 속도가 빨라지는 문제점을 프록시마AI를 통하여 가짜 뉴스가 SNS 등에 전파되는 것을 미연에 방지할 수 있습니다.

2. **스팸 봇을 제거할 수 있습니다.** 스팸 봇은 스팸을 활성화하거나 전송할 목적으로 설계된 프로그램입니다. 스팸 봇을 제거하여 SNS 뿐만아닌 각종 웹사이트나 이메일 사용자들에게 잘못된 정보를 전달하는 것을 방지할 수 있습니다.
